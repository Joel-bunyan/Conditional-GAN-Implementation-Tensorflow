{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/horse2zebra.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CBeVS7MV0pe",
        "outputId": "bc95c849-9fcd-4391-aa1c-9c2d36bfd90c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-02 16:02:56--  https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/horse2zebra.zip\n",
            "Resolving people.eecs.berkeley.edu (people.eecs.berkeley.edu)... 128.32.244.190\n",
            "Connecting to people.eecs.berkeley.edu (people.eecs.berkeley.edu)|128.32.244.190|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 116867962 (111M) [application/zip]\n",
            "Saving to: ‘horse2zebra.zip’\n",
            "\n",
            "horse2zebra.zip     100%[===================>] 111.45M  18.9MB/s    in 6.9s    \n",
            "\n",
            "2023-07-02 16:03:04 (16.2 MB/s) - ‘horse2zebra.zip’ saved [116867962/116867962]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/horse2zebra.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')"
      ],
      "metadata": {
        "id": "5oELTsuDWwLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of preparing the horses and zebra dataset\n",
        "from os import listdir\n",
        "from numpy import asarray\n",
        "from numpy import vstack\n",
        "from keras.utils import img_to_array\n",
        "from keras.utils import load_img\n",
        "from numpy import savez_compressed\n",
        "\n",
        "# load all images in a directory into memory\n",
        "def load_images(path, size=(256,256)):\n",
        "\tdata_list = list()\n",
        "\t# enumerate filenames in directory, assume all are images\n",
        "\tfor filename in listdir(path):\n",
        "\t\t# load and resize the image\n",
        "\t\tpixels = load_img(path + filename, target_size=size)\n",
        "\t\t# convert to numpy array\n",
        "\t\tpixels = img_to_array(pixels)\n",
        "\t\t# store\n",
        "\t\tdata_list.append(pixels)\n",
        "\treturn asarray(data_list)\n",
        "\n",
        "# dataset path\n",
        "path = 'horse2zebra/'\n",
        "# load dataset A\n",
        "dataA1 = load_images(path + 'trainA/')\n",
        "dataAB = load_images(path + 'testA/')\n",
        "dataA = vstack((dataA1, dataAB))\n",
        "print('Loaded dataA: ', dataA.shape)\n",
        "# load dataset B\n",
        "dataB1 = load_images(path + 'trainB/')\n",
        "dataB2 = load_images(path + 'testB/')\n",
        "dataB = vstack((dataB1, dataB2))\n",
        "print('Loaded dataB: ', dataB.shape)\n",
        "# save as compressed numpy array\n",
        "filename = 'horse2zebra_256.npz'\n",
        "savez_compressed(filename, dataA, dataB)\n",
        "print('Saved dataset: ', filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDYyvdvpWed_",
        "outputId": "58770edd-a694-4cf8-cff5-ca938c9615ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataA:  (1187, 256, 256, 3)\n",
            "Loaded dataB:  (1474, 256, 256, 3)\n",
            "Saved dataset:  horse2zebra_256.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHPGeXiuPrLL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        },
        "outputId": "b8abca92-dd05-42e0-ee07-b4efa776e637"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded (1187, 256, 256, 3) (1474, 256, 256, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 7s 7s/step\n",
            "1/1 [==============================] - 7s 7s/step\n",
            ">1, dA[2.210,1.370] dB[2.138,0.792] g[16.459,16.409]\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            ">2, dA[2.858,10.172] dB[2.750,4.251] g[12.078,12.469]\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 6s 6s/step\n",
            ">3, dA[5.348,7.136] dB[1.232,3.398] g[14.188,14.936]\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 6s 6s/step\n",
            ">4, dA[4.282,10.430] dB[1.674,2.848] g[13.585,11.153]\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 7s 7s/step\n",
            ">5, dA[1.769,3.169] dB[2.639,1.442] g[10.676,8.548]\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 7s 7s/step\n",
            ">6, dA[1.406,2.475] dB[3.075,3.794] g[8.943,8.763]\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            ">7, dA[0.522,0.785] dB[0.876,0.784] g[14.321,15.694]\n",
            "1/1 [==============================] - 7s 7s/step\n",
            "1/1 [==============================] - 5s 5s/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-c21a67f4052b>\u001b[0m in \u001b[0;36m<cell line: 278>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0mc_model_BtoA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_composite_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model_BtoA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_model_AtoB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;31m# train models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_model_AtoB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_model_BtoA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_model_AtoB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_model_BtoA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-c21a67f4052b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset)\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0mdA_loss2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_model_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_fakeA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fakeA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0;31m# update generator A->B via adversarial and cycle loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                 \u001b[0mg_loss1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_model_AtoB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_realA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_realB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_realB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_realB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_realA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_realB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m                 \u001b[0;31m# update discriminator for B -> [real/fake]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0mdB_loss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_model_B\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_realB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_realB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   2508\u001b[0m             )\n\u001b[1;32m   2509\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2510\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2512\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from random import random\n",
        "from numpy import load\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import asarray\n",
        "from numpy.random import randint\n",
        "from keras.optimizers import Adam\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# define the discriminator model\n",
        "def define_discriminator(image_shape):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# source image input\n",
        "\tin_image = Input(shape=image_shape)\n",
        "\t# C64\n",
        "\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(in_image)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# C128\n",
        "\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = BatchNormalization(axis=-1)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# C256\n",
        "\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = BatchNormalization(axis=-1)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# C512\n",
        "\td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = BatchNormalization(axis=-1)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# second last output layer\n",
        "\td = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
        "\td = BatchNormalization(axis=-1)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# patch output\n",
        "\tpatch_out = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
        "\t# define model\n",
        "\tmodel = Model(in_image, patch_out)\n",
        "\t# compile model\n",
        "\tmodel.compile(loss='mse', optimizer=Adam(lr=0.0002, beta_1=0.5), loss_weights=[0.5])\n",
        "\treturn model\n",
        "\n",
        "# generator a resnet block\n",
        "def resnet_block(n_filters, input_layer):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# first layer convolutional layer\n",
        "\tg = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(input_layer)\n",
        "\tg = BatchNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# second convolutional layer\n",
        "\tg = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(g)\n",
        "\tg = BatchNormalization(axis=-1)(g)\n",
        "\t# concatenate merge channel-wise with input layer\n",
        "\tg = Concatenate()([g, input_layer])\n",
        "\treturn g\n",
        "\n",
        "# define the standalone generator model\n",
        "def define_generator(image_shape, n_resnet=9):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# image input\n",
        "\tin_image = Input(shape=image_shape)\n",
        "\t# c7s1-64\n",
        "\tg = Conv2D(64, (7,7), padding='same', kernel_initializer=init)(in_image)\n",
        "\tg = BatchNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# c128\n",
        "\tg = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "\tg = BatchNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# c256\n",
        "\tg = Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "\tg = BatchNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# R256\n",
        "\tfor _ in range(n_resnet):\n",
        "\t\tg = resnet_block(256, g)\n",
        "\t# u128\n",
        "\tg = Conv2DTranspose(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "\tg = BatchNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# u64\n",
        "\tg = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "\tg = BatchNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# c7s1-3\n",
        "\tg = Conv2D(3, (7,7), padding='same', kernel_initializer=init)(g)\n",
        "\tg = BatchNormalization(axis=-1)(g)\n",
        "\tout_image = Activation('tanh')(g)\n",
        "\t# define model\n",
        "\tmodel = Model(in_image, out_image)\n",
        "\treturn model\n",
        "\n",
        "# define a composite model for updating generators by adversarial and cycle loss\n",
        "def define_composite_model(g_model_1, d_model, g_model_2, image_shape):\n",
        "\t# ensure the model we're updating is trainable\n",
        "\tg_model_1.trainable = True\n",
        "\t# mark discriminator as not trainable\n",
        "\td_model.trainable = False\n",
        "\t# mark other generator model as not trainable\n",
        "\tg_model_2.trainable = False\n",
        "\t# discriminator element\n",
        "\tinput_gen = Input(shape=image_shape)\n",
        "\tgen1_out = g_model_1(input_gen)\n",
        "\toutput_d = d_model(gen1_out)\n",
        "\t# identity element\n",
        "\tinput_id = Input(shape=image_shape)\n",
        "\toutput_id = g_model_1(input_id)\n",
        "\t# forward cycle\n",
        "\toutput_f = g_model_2(gen1_out)\n",
        "\t# backward cycle\n",
        "\tgen2_out = g_model_2(input_id)\n",
        "\toutput_b = g_model_1(gen2_out)\n",
        "\t# define model graph\n",
        "\tmodel = Model([input_gen, input_id], [output_d, output_id, output_f, output_b])\n",
        "\t# define optimization algorithm configuration\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\t# compile model with weighting of least squares loss and L1 loss\n",
        "\tmodel.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 10, 10], optimizer=opt)\n",
        "\treturn model\n",
        "\n",
        "# load and prepare training images\n",
        "def load_real_samples(filename):\n",
        "\t# load the dataset\n",
        "\tdata = load(filename)\n",
        "\t# unpack arrays\n",
        "\tX1, X2 = data['arr_0'], data['arr_1']\n",
        "\t# scale from [0,255] to [-1,1]\n",
        "\tX1 = (X1 - 127.5) / 127.5\n",
        "\tX2 = (X2 - 127.5) / 127.5\n",
        "\treturn [X1, X2]\n",
        "\n",
        "# select a batch of random samples, returns images and target\n",
        "def generate_real_samples(dataset, n_samples, patch_shape):\n",
        "\t# choose random instances\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\t# retrieve selected images\n",
        "\tX = dataset[ix]\n",
        "\t# generate 'real' class labels (1)\n",
        "\ty = ones((n_samples, patch_shape, patch_shape, 1))\n",
        "\treturn X, y\n",
        "\n",
        "# generate a batch of images, returns images and targets\n",
        "def generate_fake_samples(g_model, dataset, patch_shape):\n",
        "\t# generate fake instance\n",
        "\tX = g_model.predict(dataset)\n",
        "\t# create 'fake' class labels (0)\n",
        "\ty = zeros((len(X), patch_shape, patch_shape, 1))\n",
        "\treturn X, y\n",
        "\n",
        "# save the generator models to file\n",
        "def save_models(step, g_model_AtoB, g_model_BtoA):\n",
        "\t# save the first generator model\n",
        "\tfilename1 = 'g_model_AtoB_%06d.h5' % (step+1)\n",
        "\tg_model_AtoB.save(filename1)\n",
        "\t# save the second generator model\n",
        "\tfilename2 = 'g_model_BtoA_%06d.h5' % (step+1)\n",
        "\tg_model_BtoA.save(filename2)\n",
        "\tprint('>Saved: %s and %s' % (filename1, filename2))\n",
        "\n",
        "# generate samples and save as a plot and save the model\n",
        "def summarize_performance(step, g_model, trainX, name, n_samples=5):\n",
        "\t# select a sample of input images\n",
        "\tX_in, _ = generate_real_samples(trainX, n_samples, 0)\n",
        "\t# generate translated images\n",
        "\tX_out, _ = generate_fake_samples(g_model, X_in, 0)\n",
        "\t# scale all pixels from [-1,1] to [0,1]\n",
        "\tX_in = (X_in + 1) / 2.0\n",
        "\tX_out = (X_out + 1) / 2.0\n",
        "\t# plot real images\n",
        "\tfor i in range(n_samples):\n",
        "\t\tpyplot.subplot(2, n_samples, 1 + i)\n",
        "\t\tpyplot.axis('off')\n",
        "\t\tpyplot.imshow(X_in[i])\n",
        "\t# plot translated image\n",
        "\tfor i in range(n_samples):\n",
        "\t\tpyplot.subplot(2, n_samples, 1 + n_samples + i)\n",
        "\t\tpyplot.axis('off')\n",
        "\t\tpyplot.imshow(X_out[i])\n",
        "\t# save plot to file\n",
        "\tfilename1 = '%s_generated_plot_%06d.png' % (name, (step+1))\n",
        "\tpyplot.savefig(filename1)\n",
        "\tpyplot.close()\n",
        "\n",
        "# update image pool for fake images\n",
        "def update_image_pool(pool, images, max_size=50):\n",
        "\tselected = list()\n",
        "\tfor image in images:\n",
        "\t\tif len(pool) < max_size:\n",
        "\t\t\t# stock the pool\n",
        "\t\t\tpool.append(image)\n",
        "\t\t\tselected.append(image)\n",
        "\t\telif random() < 0.5:\n",
        "\t\t\t# use image, but don't add it to the pool\n",
        "\t\t\tselected.append(image)\n",
        "\t\telse:\n",
        "\t\t\t# replace an existing image and use replaced image\n",
        "\t\t\tix = randint(0, len(pool))\n",
        "\t\t\tselected.append(pool[ix])\n",
        "\t\t\tpool[ix] = image\n",
        "\treturn asarray(selected)\n",
        "\n",
        "# train cyclegan models\n",
        "def train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset):\n",
        "\t# define properties of the training run\n",
        "\tn_epochs, n_batch, = 100, 1\n",
        "\t# determine the output square shape of the discriminator\n",
        "\tn_patch = d_model_A.output_shape[1]\n",
        "\t# unpack dataset\n",
        "\ttrainA, trainB = dataset\n",
        "\t# prepare image pool for fakes\n",
        "\tpoolA, poolB = list(), list()\n",
        "\t# calculate the number of batches per training epoch\n",
        "\tbat_per_epo = int(len(trainA) / n_batch)\n",
        "\t# calculate the number of training iterations\n",
        "\tn_steps = bat_per_epo * n_epochs\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_steps):\n",
        "\t\t# select a batch of real samples\n",
        "\t\tX_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch)\n",
        "\t\tX_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch)\n",
        "\t\t# generate a batch of fake samples\n",
        "\t\tX_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n",
        "\t\tX_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n",
        "\t\t# update fakes from pool\n",
        "\t\tX_fakeA = update_image_pool(poolA, X_fakeA)\n",
        "\t\tX_fakeB = update_image_pool(poolB, X_fakeB)\n",
        "\t\t# update generator B->A via adversarial and cycle loss\n",
        "\t\tg_loss2, _, _, _, _  = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n",
        "\t\t# update discriminator for A -> [real/fake]\n",
        "\t\tdA_loss1 = d_model_A.train_on_batch(X_realA, y_realA)\n",
        "\t\tdA_loss2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)\n",
        "\t\t# update generator A->B via adversarial and cycle loss\n",
        "\t\tg_loss1, _, _, _, _ = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])\n",
        "\t\t# update discriminator for B -> [real/fake]\n",
        "\t\tdB_loss1 = d_model_B.train_on_batch(X_realB, y_realB)\n",
        "\t\tdB_loss2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)\n",
        "\t\t# summarize performance\n",
        "\t\tprint('>%d, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]' % (i+1, dA_loss1,dA_loss2, dB_loss1,dB_loss2, g_loss1,g_loss2))\n",
        "\t\t# evaluate the model performance every so often\n",
        "\t\tif (i+1) % (bat_per_epo * 1) == 0:\n",
        "\t\t\t# plot A->B translation\n",
        "\t\t\tsummarize_performance(i, g_model_AtoB, trainA, 'AtoB')\n",
        "\t\t\t# plot B->A translation\n",
        "\t\t\tsummarize_performance(i, g_model_BtoA, trainB, 'BtoA')\n",
        "\t\tif (i+1) % (bat_per_epo * 5) == 0:\n",
        "\t\t\t# save the models\n",
        "\t\t\tsave_models(i, g_model_AtoB, g_model_BtoA)\n",
        "\n",
        "# load image data\n",
        "dataset = load_real_samples('horse2zebra_256.npz')\n",
        "print('Loaded', dataset[0].shape, dataset[1].shape)\n",
        "# define input shape based on the loaded dataset\n",
        "image_shape = dataset[0].shape[1:]\n",
        "# generator: A -> B\n",
        "g_model_AtoB = define_generator(image_shape)\n",
        "# generator: B -> A\n",
        "g_model_BtoA = define_generator(image_shape)\n",
        "# discriminator: A -> [real/fake]\n",
        "d_model_A = define_discriminator(image_shape)\n",
        "# discriminator: B -> [real/fake]\n",
        "d_model_B = define_discriminator(image_shape)\n",
        "# composite: A -> B -> [real/fake, A]\n",
        "c_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape)\n",
        "# composite: B -> A -> [real/fake, B]\n",
        "c_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape)\n",
        "# train models\n",
        "train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DlzcFeouZVB4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}